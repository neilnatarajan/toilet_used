{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv \n",
    "import gzip \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import linear_model\n",
    "from collections import defaultdict\n",
    "\n",
    "# reading in the data to get Field Names\n",
    "data = []\n",
    "with open('Mortality_05_UT.csv', 'rb') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    fieldNames = []\n",
    "    for row in spamreader:\n",
    "        fieldNames.append(row)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get meta data \n",
    "fieldNames = fieldNames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create List of dictionaries for each record in the dataset\n",
    "with open('Mortality_05_UT.csv') as csvfile:\n",
    "    data = []\n",
    "    reader = csv.DictReader(csvfile,fieldnames=fieldNames)\n",
    "    count = 0 \n",
    "    for row in reader:\n",
    "        if count != 0:\n",
    "            data.append(row)\n",
    "        count +=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove records that have an empty age field \n",
    "cleanData = []\n",
    "for datum in data:\n",
    "    toAppend = True\n",
    "    if datum['age'] is '':\n",
    "        toAppend = False\n",
    "        \n",
    "    for k in datum.keys():\n",
    "        if datum[k] is '':\n",
    "            datum[k] = -100\n",
    "    if toAppend:\n",
    "        cleanData.append(datum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part of preprocessing \n",
    "useless = ['m_id','client_m_id','hl_id','house_no','PSU_ID','m_serial_no','date_of_death','month_of_death','year_of_death','is_death_reg','place_of_death','is_death_certificate_received','serial_num_of_infant_mother','death_period','months_of_pregnancy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#part of preprocessing \n",
    "useful_stuff = ['id','state','house_hold_no','district','rural','stratum_code',\\\n",
    "               'deceased_sex','treatment_source','order_of_birth','sex','age',\\\n",
    "               'religion','marital_status','currently_attending_school', \\\n",
    "               'reason_for_not_attending_school','highest_qualification','occupation_status'\\\n",
    "              'disability_status','regular_treatment','regular_treatment_source','chew','smoke'\\\n",
    "              'injury_treatment_type','alcohol','house_status','owner_status','drinking_water_source'\\\n",
    "              'is_water_filter','water_filteration','toilet_used','is_toilet_shared','household_have_electricity'\\\n",
    "              'lighting_source','cooking_fuel','no_of_dwelling_rooms','kitchen_availability','is_radio',\\\n",
    "              'is_televison','is_computer','is_telephone', 'is_washing_machine', 'is_refrigerator', \\\n",
    "              'is_sewing_machine', 'is_bicycle', 'is_scooter', 'is_car', 'is_tractor', 'is_water_pump', \\\n",
    "              'cart', 'land_possessed', 'iscoveredbyhealthscheme', 'injury_treatment_type'\\\n",
    "              'house_structure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final features in consolidated data \n",
    "columns = ['id','state','house_hold_no','district','rural','stratum_code',\\\n",
    "'private_parts','order_of_birth','age','religion','marital_status'\\\n",
    ",'currently_attending_school', 'reason_for_not_attending_school','highest_qualification','occupation_status','disability_status','regular_treatment','regular_treatment_source','chew','smoke'\\\n",
    ",'injury_treatment_type','alcohol','house_status','owner_status','drinking_water_source'\\\n",
    ",'water_filteration','toilet_used','is_toilet_shared','household_have_electricity'\\\n",
    ",'lighting_source','cooking_fuel','no_of_dwelling_rooms','kitchen_availability','is_radio',\\\n",
    "'is_television','is_computer','is_telephone', 'is_washing_machine', 'is_refrigerator','is_sewing_machine', 'is_bicycle', 'is_scooter', 'is_car', 'is_tractor', 'is_water_pump', \\\n",
    "'cart','land_possessed','iscoveredbyhealthscheme'\\\n",
    ",'house_structure']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# number of categories for each type of one hot encoding \n",
    "indexDict = defaultdict(int)\n",
    "\n",
    "indexDict['rural'] = 2\n",
    "indexDict['private_parts'] = 2\n",
    "indexDict['religion'] = 8\n",
    "indexDict['marital_status'] = 8\n",
    "indexDict['currently_attending_school'] = 3\n",
    "indexDict['reason_for_not_attending_school'] = 9\n",
    "indexDict['regular_treatment'] = 3\n",
    "indexDict['regular_treatment_source'] = 15\n",
    "indexDict['highest_qualification'] = 10\n",
    "indexDict['occupation_status'] = 16\n",
    "indexDict['disability_status'] = 8\n",
    "indexDict['chew'] = 8\n",
    "indexDict['smoke'] = 5\n",
    "indexDict['injury_treatment_type'] = 8\n",
    "indexDict['alcohol'] = 5\n",
    "indexDict['house_status'] = 4 \n",
    "indexDict['owner_status'] = 3\n",
    "indexDict['drinking_water_source'] = 9\n",
    "indexDict['water_filteration'] = 8\n",
    "indexDict['toilet_used'] = 10\n",
    "indexDict['is_toilet_shared'] = 2\n",
    "indexDict['household_have_electricity'] = 2\n",
    "indexDict['lighting_source'] = 6\n",
    "indexDict['cooking_fuel'] = 10\n",
    "indexDict['kitchen_availability'] = 5\n",
    "indexDict['is_radio'] = 2\n",
    "indexDict['is_television'] = 2\n",
    "indexDict['is_computer'] = 3\n",
    "indexDict['is_telephone'] = 4\n",
    "indexDict['is_washing_machine'] = 2\n",
    "indexDict['is_refrigerator'] = 2\n",
    "indexDict['is_sewing_machine'] = 2\n",
    "indexDict['is_bicycle'] = 2\n",
    "indexDict['is_scooter'] = 2\n",
    "indexDict['is_car'] = 2\n",
    "indexDict['is_tractor'] = 2\n",
    "indexDict['is_water_pump'] = 2\n",
    "indexDict['cart'] = 4\n",
    "indexDict['land_possessed'] = 6\n",
    "indexDict['iscoveredbyhealthscheme'] = 3\n",
    "indexDict['house_structure'] = 4\n",
    "\n",
    "# features that don't need one hot encoding \n",
    "mansNotHot = [\n",
    " 'house_hold_no',\n",
    " 'stratum_code',\n",
    " 'order_of_birth',\n",
    " 'no_of_dwelling_rooms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "consolidated_data = []\n",
    "\n",
    "for d in cleanData:\n",
    "    tempDict = defaultdict(int)\n",
    "    sex = None \n",
    "#     remapping categories that have something mapped to 0 \n",
    "    for c in columns:\n",
    "        if c is 'private_parts':\n",
    "            if d['sex'] != -100:\n",
    "                sex = int(d['sex'])\n",
    "            elif d['deceased_sex'] != -100:\n",
    "                sex = int(d['deceased_sex'])\n",
    "            tempDict['private_parts'] = sex \n",
    "        elif c is 'regular_treatment_source':\n",
    "            if d['regular_treatment_source']=='99':\n",
    "                tempDict[c] = 14\n",
    "            elif d['regular_treatment_source'] =='00':\n",
    "                tempDict[c] = 15\n",
    "        elif c is 'highest_qualification':\n",
    "            if d['highest_qualification'] =='0':\n",
    "                tempDict[c] = 10\n",
    "        elif c is 'disability_status':\n",
    "            if d['disability_status'] == '0':\n",
    "                tempDict[c] = 8\n",
    "        elif c is 'chew':\n",
    "            if d['chew'] == '0':\n",
    "                tempDict[c] = 8\n",
    "        elif c is 'smoke':\n",
    "            if d['smoke'] == '0':\n",
    "                tempDict[c] = 5\n",
    "        elif c is 'injury_treatment_type':\n",
    "            if d['injury_treatment_type'] == '0':\n",
    "                tempDict[c] = 8\n",
    "        elif c is 'alcohol':\n",
    "            if d['alcohol'] == '0':\n",
    "                tempDict[c] = indexDict['alcohol']\n",
    "        elif c is 'toilet_used':\n",
    "            if d['toilet_used'] == '0':\n",
    "                tempDict[c] = indexDict['toilet_used']\n",
    "        elif c is 'cooking_fuel':\n",
    "            if d['cooking_fuel'] == '0':\n",
    "                tempDict[c] = indexDict['cooking_fuel']\n",
    "        else:\n",
    "            #no remapping needed \n",
    "            tempDict[c] = int(d[c])\n",
    "    consolidated_data.append(tempDict)\n",
    "\n",
    "print 'done'\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Neil is a beast \n",
    "\n",
    "#age\n",
    "def checkAge(datum):\n",
    "    return datum['age']\n",
    "\n",
    "# add one hot encodings \n",
    "def appendFeats(datum,cat):\n",
    "    val = int(datum[cat])\n",
    "    \n",
    "    retList = [0]*indexDict[cat]\n",
    "    if val !=-100:\n",
    "        retList[val-1] = 1\n",
    "    return retList\n",
    "\n",
    "def getAvg(cat):\n",
    "    count = 0 \n",
    "    num = 0 \n",
    "    for d in consolidated_data:\n",
    "        if int(d[cat]) != -100:\n",
    "            count += int(d[cat])\n",
    "            num +=1\n",
    "    return 1.0*count/num\n",
    "avgList = defaultdict(float)\n",
    "for i in mansNotHot:\n",
    "    avgList[i] = getAvg(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for datum in cleanData, datum is a dictionary\n",
    "def feature(datum):\n",
    "    feat = []\n",
    "    \n",
    "    #not hot encoding  \n",
    "    for category in mansNotHot:\n",
    "        if datum[category] ==-100:\n",
    "            feat.append(avgList[category])\n",
    "        else:\n",
    "            feat.append(datum[category])\n",
    "    #one hot encoding \n",
    "    for category in indexDict.keys():\n",
    "        feat += appendFeats(datum,category)\n",
    "    return feat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_feat = [feature(d) for d in consolidated_data]\n",
    "y_label = [checkAge(d) for d in consolidated_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "pca = PCA(n_components=50)\n",
    "# pca.fit(X_feat)\n",
    "# print \"PCA:\",pca.components_\n",
    "# proj have 10 best features \n",
    "X_proj = pca.fit_transform(X_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import urllib\n",
    "import scipy.optimize\n",
    "import random\n",
    "\n",
    "theta,residuals,rank,s = np.linalg.lstsq(X_proj, y_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.70651726   0.87471054  -2.5271553    3.05148241   0.37231707\n",
      "   0.02183914  -1.98441142  -1.85932442   1.40856083   0.31731558\n",
      "   5.38897353  -7.39844183   3.74862214   0.92438689  -1.31689254\n",
      "   0.72919049   0.30922748  -0.55351142   1.88095022   0.24500648\n",
      "   1.60824973   0.17198962   3.37185943  -0.14760974   2.7792958\n",
      "   0.49184643   3.39549061   2.97190592   0.55246324   1.61188058\n",
      "  -2.31558307  -0.51411711   0.36677     -2.32148561  -3.43138564\n",
      "   5.7801156    0.06202441  -0.93106721   1.18884359  -0.06635819\n",
      "   8.99149988   2.82745551  13.48895272  -2.69876866   2.81011047\n",
      " -11.28620687  -2.25177132   1.51578461 -11.06964666  -0.6927694 ]\n"
     ]
    }
   ],
   "source": [
    "print theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for x in X_proj:\n",
    "    predictions.append(sum([xi*t for (xi,t) in zip(x,theta)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalSE = 0 \n",
    "for (a,b) in zip(predictions,y_label):\n",
    "    totalSE+=(a-b)**2\n",
    "mse = 1.0*totalSE/len(y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-7.3615950578033074, 45)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[1],y_label[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: tune parameters to get better predictions, but code done "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
